# ü§ñ Robots.txt - Directives pour les moteurs de recherche
# Permet √† Google, Bing, etc. de crawler le site correctement

# R√®gles par d√©faut pour tous les bots
User-agent: *
Allow: /
Allow: /blog
Allow: /blog/*
Allow: /services
Allow: /pricing
Allow: /about
Allow: /contact

# Interdire les pages admin et API
Disallow: /admin
Disallow: /api
Disallow: /admin-dashboard
Disallow: /*.json$
Disallow: /*.xml$

# Interdire les fichiers temporaires
Disallow: /tmp/
Disallow: /temp/
Disallow: /.next/

# Crawl delay (d√©lai entre les requ√™tes)
Crawl-delay: 1

# R√®gles sp√©cifiques pour Google
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# R√®gles sp√©cifiques pour Bing
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# R√®gles sp√©cifiques pour Yandex
User-agent: YandexBot
Allow: /
Crawl-delay: 1

# Sitemap
Sitemap: https://alphalaundry.com/sitemap.xml
